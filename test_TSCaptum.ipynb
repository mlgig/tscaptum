{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:48:51.956021Z",
     "start_time": "2024-05-29T11:48:50.437154Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from aeon.datasets import  load_from_tsfile\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aeon.transformations.collection.convolution_based import MiniRocketMultivariate\n",
    "import numpy as np\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3294ea6bac3bb843",
   "metadata": {},
   "source": [
    "# load regression and classification datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13417e220faafd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:48:52.504706Z",
     "start_time": "2024-05-29T11:48:51.957161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression train and test (42, 24, 144) (42,)\n",
      "univariate classification (419, 1, 500) (179, 1, 500)\n",
      "multivariate classification (1426, 8, 161) (595, 8, 161)\n"
     ]
    }
   ],
   "source": [
    "data_location = './src/TsCaptum/data/'\n",
    "X_train_reg, y_train_reg = load_from_tsfile( join( data_location, \"AppliancesEnergy_TRAIN.ts\"))\n",
    "X_test_reg, y_test_reg = load_from_tsfile( join( data_location,\"AppliancesEnergy_TEST.ts\"))\n",
    "print(\"regression train and test\",X_test_reg.shape, y_test_reg.shape)\n",
    "\n",
    "CMJ = np.load( join( data_location, \"CMJ_univariate.npy\"),allow_pickle=True).item()\n",
    "CMJ_X_train =CMJ[\"train\"][\"X\"]\n",
    "CMJ_X_test = CMJ[\"test\"][\"X\"]\n",
    "CMJ_y_train =CMJ[\"train\"][\"y\"]\n",
    "CMJ_y_test = CMJ[\"test\"][\"y\"]\n",
    "print(\"univariate classification\", CMJ_X_train.shape, CMJ_X_test.shape)\n",
    "\n",
    "MP = np.load( join( data_location, \"MP_centered.npy\"), allow_pickle=True).item()\n",
    "MP_X_train =MP[\"train\"][\"X\"]\n",
    "MP_X_test = MP[\"test\"][\"X\"]\n",
    "MP_y_train =MP[\"train\"][\"y\"]\n",
    "MP_y_test = MP[\"test\"][\"y\"]\n",
    "print(\"multivariate classification\", MP_X_train.shape, MP_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5edc99c3663fea",
   "metadata": {},
   "source": [
    "# train same classifiers anc checkout how the library works\n",
    "after you have trained a classifier, have your sample to explain it's just a 2 step process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5eb17cc3824d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:48:52.845870Z",
     "start_time": "2024-05-29T11:48:52.505933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric is 0.6169356987334496\n"
     ]
    }
   ],
   "source": [
    "regressor = make_pipeline(MiniRocketMultivariate(n_jobs=1),\n",
    "                          StandardScaler(),LinearRegression(n_jobs=-1))\n",
    "\n",
    "regressor.fit(X_train_reg, y_train_reg)\n",
    "print(\"metric is\", regressor.score(X_test_reg,y_test_reg) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137785057a72a68",
   "metadata": {},
   "source": [
    "we're explaining only 20 samples as a demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eea21bd9bbfcb06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:48:54.751040Z",
     "start_time": "2024-05-29T11:48:54.748374Z"
    }
   },
   "outputs": [],
   "source": [
    "n_to_explain =20\n",
    "X_test_reg, y_test_reg = X_test_reg[:n_to_explain], y_test_reg[:n_to_explain]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6957fac234541",
   "metadata": {},
   "source": [
    "# Feature Ablation\n",
    "now we are explaining!\n",
    "1) instantiate your attribution method, the constructor takes only one mandatory argument namely the predictor and one optional argument its type (classifier or regressor). In case the last one isn't provided it's inferred by tha availability of predict_proba in the predictor\n",
    "2) one you have the object call the method explain which return the saliency map. Only one mandatory argument that is the samples to be explained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88cb3a463327003c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:04.579396Z",
     "start_time": "2024-05-29T11:48:55.956169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:06,  3.56it/s]                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saliency map shape equal to input shape: (20, 24, 144) (20, 24, 144) \n",
      " attributions for first 5 time points in first 5 channel:\n",
      " [[-0.0949707  -0.0949707  -0.0949707  -0.0949707  -0.0949707 ]\n",
      " [-0.4078579  -0.4078579  -0.4078579  -0.4078579  -0.4078579 ]\n",
      " [ 0.29314327  0.29314327  0.29314327  0.29314327  0.29314327]\n",
      " [ 0.9225435   0.9225435   0.9225435   0.9225435   0.9225435 ]\n",
      " [-0.8509064  -0.8509064  -0.8509064  -0.8509064  -0.8509064 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./src/')\n",
    "from TsCaptum.explainers import Feature_Ablation\n",
    "myFA = Feature_Ablation(regressor)\n",
    "exp = myFA.explain(samples=X_test_reg)\n",
    "print( \"saliency map shape equal to input shape:\", exp.shape, X_test_reg.shape,\n",
    "       \"\\n attributions for first 5 time points in first 5 channel:\\n\", exp[0,:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbaf4d0f258bf72",
   "metadata": {},
   "source": [
    "apart from sample, the explain method has some additional parameters\n",
    "\n",
    "\t\t:param labels:      labels associated to samples in case of classification\n",
    "\t\t:param batch_size:  the batch_size to be used i.e. number of samples to be explained at the same time\n",
    "\t\t:param n_segments:  number of segments the timeseries is dived to. If you want to explain point-wise provide -1 as value\n",
    "\t\t:param normalise:   whether or not to normalise the result\n",
    "\t\t:param baseline:    the baseline which will substitute time series's values when ablated. It can be either a scalar (each time series's value is substituted by this scalar)  or a single time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ddef0a0e370b00",
   "metadata": {},
   "source": [
    "#TODO add option for normalisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979ea58023ff042a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:14.111338Z",
     "start_time": "2024-05-29T11:49:04.580560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : min and max values -3.8351393 1.70368\n",
      "1 : min and max values -4.5015717 1.8390827\n",
      "2 : min and max values -4.5740843 1.7647781\n",
      "3 : min and max values -4.38286 1.8778057\n",
      "4 : min and max values -4.7104874 2.1110039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 20/20 [00:04<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 min and max values -1.0 0.44422898\n",
      "1 min and max values -1.0 0.40854236\n",
      "2 min and max values -1.0 0.38582107\n",
      "3 min and max values -1.0 0.42844298\n",
      "4 min and max values -1.0 0.44814977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp = myFA.explain(samples=X_test_reg,batch_size=10, n_segments=5)\n",
    "for i in range(5):\n",
    "    print(i, \": min and max values\", exp[i].min(), exp[i].max())\n",
    "    \n",
    "exp_normalized = myFA.explain(samples=X_test_reg,batch_size=10, n_segments=5, normalise=True)\n",
    "for i in range(5):\n",
    "    print(i,\"min and max values\", exp_normalized[i].min(), exp_normalized[i].max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab29a164383d36",
   "metadata": {},
   "source": [
    "labels parameter only make sense if you're using a classifier\n",
    "let's switch to another dataset and classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b824b31e630377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:18.865560Z",
     "start_time": "2024-05-29T11:49:14.112429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUANT accuracy is 0.9720670391061452\n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.dictionary_based import WEASEL\n",
    "clf = WEASEL(window_inc=4, support_probabilities=True)\n",
    "clf.fit(CMJ_X_train, CMJ_y_train)\n",
    "print (\"QUANT accuracy is\",clf.score(CMJ_X_test,CMJ_y_test),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a3ebaa3fd4645c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:18.868888Z",
     "start_time": "2024-05-29T11:49:18.866616Z"
    }
   },
   "outputs": [],
   "source": [
    "n_to_explain = 20\n",
    "CMJ_X_test, CMJ_y_test = CMJ_X_test[:n_to_explain], CMJ_y_test[:n_to_explain]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39aaa0a390feb14",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4450816ad179ce54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:35.920806Z",
     "start_time": "2024-05-29T11:49:18.869555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:20,  1.19it/s]                                                                   \n"
     ]
    }
   ],
   "source": [
    "from TsCaptum.explainers import Shapley_Value_Sampling as SHAP\n",
    "mySHAP = SHAP(clf)\n",
    "exp = mySHAP.explain(CMJ_X_test, labels=CMJ_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5faeadb30dfd99",
   "metadata": {},
   "source": [
    "# Kernel SHAP and LIME\n",
    "for kernel SHAP and Lime the Captum framework suggests to use a batch size = 1, we are enforcing this propriety "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6656c4c5052642b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:42.012190Z",
     "start_time": "2024-05-29T11:49:35.921627Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/miniconda3/envs/TSCaptum_pypi20/lib/python3.8/site-packages/TsCaptum/explainers.py:190: UserWarning: batch_size set to 1 as suggested by Captum for Lime and KernelSHAP\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████| 20/20 [00:06<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from TsCaptum.explainers import Kernel_Shap\n",
    "myKernelSHAP = Kernel_Shap(clf)\n",
    "exp = myKernelSHAP.explain(CMJ_X_test, labels=CMJ_y_test, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e0b30b76683ab6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:49:48.250671Z",
     "start_time": "2024-05-29T11:49:42.012913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/miniconda3/envs/TSCaptum_pypi20/lib/python3.8/site-packages/TsCaptum/explainers.py:217: UserWarning: batch_size set to 1 as suggested by Captum for Lime and KernelSHAP\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████| 20/20 [00:06<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from TsCaptum.explainers import  LIME\n",
    "myLIME = LIME(clf)\n",
    "exp = myLIME.explain(CMJ_X_test, labels=CMJ_y_test, batch_size=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bd2e034c19059",
   "metadata": {},
   "source": [
    "another important optional argument is baseline i.e. the value(s) replacing the time series's ones when ablated by the attributions\n",
    "two possible format for it:\n",
    " 1) a scalar i.e. a single number replacing each value to be ablated (default value is 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c0b7d529810aaf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:50:04.483497Z",
     "start_time": "2024-05-29T11:49:48.251772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:17,  1.41it/s]                                                                   \n"
     ]
    }
   ],
   "source": [
    "mySHAP = SHAP(clf)\n",
    "exp = mySHAP.explain(CMJ_X_test, labels=CMJ_y_test, baseline=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0877e5c30fc11",
   "metadata": {},
   "source": [
    "2) a time series having the same shape as the one to be explained, usually one item from the train set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b43ddbd134bc6b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:50:21.711268Z",
     "start_time": "2024-05-29T11:50:04.484366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:17,  1.34it/s]                                                                   \n"
     ]
    }
   ],
   "source": [
    "exp = mySHAP.explain(CMJ_X_test, labels=CMJ_y_test, baseline=CMJ_X_train[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d059928693bf4",
   "metadata": {},
   "source": [
    "# Feature Permutation \n",
    "this is the last explainer, the only one that not accept a baseline as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36564c3e46781103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:50:22.534095Z",
     "start_time": "2024-05-29T11:50:21.712746Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/miniconda3/envs/TSCaptum_pypi20/lib/python3.8/site-packages/TsCaptum/explainers.py:164: UserWarning: specified baseline will be ignored as Feature Permutation algorithm has its own baseline\n",
      "  warnings.warn(\n",
      "24it [00:00, 27.45it/s]                                                                   \n"
     ]
    }
   ],
   "source": [
    "from TsCaptum.explainers import Feature_Permutation\n",
    "myFP = Feature_Permutation(clf,clf_type=\"classifier\")\n",
    "exp = myFP.explain(CMJ_X_test, labels=CMJ_y_test, baseline=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892836516582dc1b",
   "metadata": {},
   "source": [
    "# finally we explain a multivariate dataset, first of all using the default arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6104cb02d4d84e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:51:40.489639Z",
     "start_time": "2024-05-29T11:50:22.534763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.7361344537815127\n"
     ]
    }
   ],
   "source": [
    "clf_MTS = make_pipeline(MiniRocketMultivariate(n_jobs=-1),\n",
    "                          StandardScaler(),LogisticRegressionCV(max_iter=200, n_jobs=-1))\n",
    "clf_MTS.fit(MP_X_train,MP_y_train)\n",
    "print(\"accuracy is\", clf_MTS.score(MP_X_test,MP_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7360295aa10d7e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:51:40.497965Z",
     "start_time": "2024-05-29T11:51:40.491828Z"
    }
   },
   "outputs": [],
   "source": [
    "n_to_explain = 5\n",
    "MP_X_test_samples, MP_y_test_samples = MP_X_test[:n_to_explain], MP_y_test[:n_to_explain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b41c684fe6b4681f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:51:41.201770Z",
     "start_time": "2024-05-29T11:51:40.499501Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:01,  7.68it/s]                                                                    \n"
     ]
    }
   ],
   "source": [
    "myFA_MTS = Feature_Ablation(clf_MTS, clf_type=\"classifier\")\n",
    "exp = myFA_MTS.explain( samples= MP_X_test_samples, labels=MP_y_test_samples, batch_size=8, n_segments=10, normalise=False, baseline=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a894cdc15e4952",
   "metadata": {},
   "source": [
    "then try different classifiers and different arguments for attribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f2501792f7f4d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:52:29.780005Z",
     "start_time": "2024-05-29T11:51:41.203243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.680672268907563\n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.dictionary_based import MUSE\n",
    "clf_MTS = MUSE(window_inc=4, use_first_order_differences=False, support_probabilities=True)\n",
    "clf_MTS.fit(MP_X_train,MP_y_train)\n",
    "print(\"accuracy is\", clf_MTS.score(MP_X_test,MP_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147380f822bcefe",
   "metadata": {},
   "source": [
    "we can checkout the n_segments purpose. #TODO write a bit more about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0d7700697decf43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:52:46.874460Z",
     "start_time": "2024-05-29T11:52:29.780880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (76,)\n",
      "1 (72,)\n",
      "2 (78,)\n",
      "3 (80,)\n",
      "4 (64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (40,)\n",
      "1 (40,)\n",
      "2 (39,)\n",
      "3 (40,)\n",
      "4 (40,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_explainer = Kernel_Shap(clf_MTS)\n",
    "exps = my_explainer.explain( samples=MP_X_test_samples, labels=MP_y_test_samples, n_segments=10)\n",
    "for i,exp in enumerate(exps):\n",
    "    print( i , np.unique(exp).shape )\n",
    "\n",
    "\n",
    "exps = my_explainer.explain( samples=MP_X_test_samples, labels=MP_y_test_samples, n_segments=5)\n",
    "for i,exp in enumerate(exps):\n",
    "\tprint( i , np.unique(exp).shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4e4737227b62bf",
   "metadata": {},
   "source": [
    "# QUANT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf93521c2e184696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:53:20.125218Z",
     "start_time": "2024-05-29T11:52:46.875281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.692436974789916\n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.interval_based import QUANTClassifier\n",
    "clf_MTS = QUANTClassifier()\n",
    "clf_MTS.fit(MP_X_train,MP_y_train)\n",
    "print(\"accuracy is\", clf_MTS.score(MP_X_test,MP_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8145420710c998d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:53:23.372885Z",
     "start_time": "2024-05-29T11:53:20.126282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:02,  3.03it/s]                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " min and max attribution without normalisation:\n",
      "0 -0.0250 \t 0.1250\n",
      "1 -0.0850 \t 0.0500\n",
      "2 -0.0150 \t 0.1150\n",
      "3 -0.0400 \t 0.0550\n",
      "4 -0.0850 \t 0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:02,  2.94it/s]                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " min and max attribution with normalisation:\n",
      "0 -1.0000 \t 0.9048\n",
      "1 -1.0000 \t 0.5882\n",
      "2 -0.0769 \t 1.0000\n",
      "3 -1.0000 \t 0.9333\n",
      "4 -1.0000 \t 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_explainer = Feature_Permutation(clf_MTS)\n",
    "\n",
    "exps = my_explainer.explain( samples=MP_X_test_samples, labels=MP_y_test_samples, n_segments=5, normalise=False)\n",
    "print(\" min and max attribution without normalisation:\")\n",
    "for i,exp in enumerate(exps):\n",
    "\tprint( i , '{:.4f}'.format(exp.min()),\"\\t\", '{:.4f}'.format(exp.max()) )\n",
    "\n",
    "exps = my_explainer.explain( samples=MP_X_test_samples, labels=MP_y_test_samples, n_segments=5, normalise=True)\n",
    "print(\" min and max attribution with normalisation:\")\n",
    "for i,exp in enumerate(exps):\n",
    "\tprint( i , '{:.4f}'.format(exp.min()),\"\\t\", '{:.4f}'.format(exp.max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb4cf8ea2d25ea",
   "metadata": {},
   "source": [
    "# Rocket classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "449d5e25f2663869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:53:24.592595Z",
     "start_time": "2024-05-29T11:53:23.373659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6957983193277311\n"
     ]
    }
   ],
   "source": [
    "from aeon.classification.convolution_based import RocketClassifier\n",
    "clf_MTS = RocketClassifier(num_kernels=500,rocket_transform=\"rocket\",n_jobs=-1)\n",
    "clf_MTS.fit(MP_X_train,MP_y_train)\n",
    "print( clf_MTS.score(MP_X_test,MP_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98888b82d49023dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T11:53:25.090619Z",
     "start_time": "2024-05-29T11:53:24.595552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:00, 10.67it/s]                                                                    \n"
     ]
    }
   ],
   "source": [
    "my_explainer = Feature_Permutation(clf_MTS)\n",
    "exp = my_explainer.explain(samples=MP_X_test_samples, labels=MP_y_test_samples, n_segments=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0842efa33107367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
