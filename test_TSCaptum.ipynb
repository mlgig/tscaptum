{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T12:27:20.518511Z",
     "start_time": "2024-05-17T12:27:18.950631Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from aeon.datasets import  load_from_tsfile\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aeon.transformations.collection.convolution_based import MiniRocketMultivariate\n",
    "from aeon.datasets import load_basic_motions, load_gunpoint\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:27:20.733726Z",
     "start_time": "2024-05-17T12:27:20.519512Z"
    }
   },
   "cell_type": "code",
   "source": "from tsCaptum.explainers import Feature_Ablation, Feature_Permutation, LIME, Kernel_Shap\n",
   "id": "bec3e4cda4a9e110",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# load regression and classification datasets",
   "id": "3294ea6bac3bb843"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:27:21.200996Z",
     "start_time": "2024-05-17T12:27:20.734574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_reg, y_train_reg = load_from_tsfile(\"./tsCaptum/data/AppliancesEnergy_TRAIN.ts\")\n",
    "X_test_reg, y_test_reg = load_from_tsfile(\"./tsCaptum/data/AppliancesEnergy_TEST.ts\")\n",
    "\n",
    "\n",
    "X_train_clf, y_train_clf = load_gunpoint(split=\"train\")\n",
    "X_test_clf, y_test_clf = load_gunpoint(split=\"test\")\n"
   ],
   "id": "f13417e220faafd9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# train quant and explain it point and segmentation-wise",
   "id": "f7a8ea696fff8a5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:27:45.553395Z",
     "start_time": "2024-05-17T12:27:45.322612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from aeon.classification.interval_based import QUANTClassifier\n",
    "clf = QUANTClassifier()\n",
    "clf.fit(X_train_clf, y_train_clf)\n",
    "print (\"QUAN accuracy is\",clf.score(X_test_clf,y_test_clf), X_train_clf.shape, X_test_clf.shape,)\n",
    "\n"
   ],
   "id": "d72a443151408291",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUAN accuracy is 0.9933333333333333 (50, 1, 150) (150, 1, 150)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:27:47.822270Z",
     "start_time": "2024-05-17T12:27:46.321941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "n_to_explain = 10\n",
    "myFP4clf = Feature_Permutation(clf)\n",
    "exp = myFP4clf.explain(  X_train_clf[:n_to_explain],   labels=y_test_clf[:n_to_explain], batch_size=2, n_segments=7)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\")\n"
   ],
   "id": "3c1b194e9949e4bf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/workspace/PhD/captum4aeon/tsCaptum/explainers.py:92: UserWarning:  batch_size set to 2 as Feature Permutation require more than 1 sample to work\n",
      "  warnings.warn(\" batch_size set to 2 as Feature Permutation require more than 1 sample to work\")\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (45,) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:28:12.010175Z",
     "start_time": "2024-05-17T12:27:47.823391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp = myFP4clf.explain(X_train_clf[:n_to_explain],labels=y_test_clf[:n_to_explain], batch_size=6)\n",
    "print( type(exp), exp.shape, \"unique values\", np.unique(exp).shape , \"\\n\\n\")\n"
   ],
   "id": "c1fcd33f1685da32",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/workspace/PhD/captum4aeon/tsCaptum/explainers.py:92: UserWarning:  batch_size set to 2 as Feature Permutation require more than 1 sample to work\n",
      "  warnings.warn(\" batch_size set to 2 as Feature Permutation require more than 1 sample to work\")\n",
      "100%|██████████| 10/10 [00:24<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (10, 1, 150) unique values (56,) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# kernel shap\n",
    "testing normalisation "
   ],
   "id": "60446cc929a701b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:28:26.925896Z",
     "start_time": "2024-05-17T12:28:12.011138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "n_to_explain = 20\n",
    "\n",
    "myKernel4clf = Kernel_Shap(clf=clf, clf_type=\"classifier\")\n",
    "exp = myKernel4clf.explain( torch.tensor(X_test_clf[:n_to_explain]), labels=y_test_clf[:n_to_explain], normalise=True)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape ,\n",
    "       \"\\n max and min values are \", exp.max(), exp.min() )\n"
   ],
   "id": "a4d3d8b192c11ba5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:14<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (2359,) \n",
      " max and min values are  1.0 -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:28:41.728912Z",
     "start_time": "2024-05-17T12:28:26.927026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now without normalisation \n",
    "exp = myKernel4clf.explain( torch.tensor(X_test_clf[:n_to_explain]), labels=y_test_clf[:n_to_explain], normalise=False)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape ,\n",
    "       \"\\n max and min values are \", exp.max(), exp.min() )"
   ],
   "id": "4854b6c433530c2c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:14<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (2547,) \n",
      " max and min values are  0.14000005 -0.08000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:29:16.560055Z",
     "start_time": "2024-05-17T12:29:01.879644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp = myKernel4clf.explain( torch.tensor(X_test_clf[:n_to_explain]), labels=y_test_clf[:n_to_explain], n_segments=5)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\")"
   ],
   "id": "e29e3a8fe650e6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:14<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (100,) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# other dataset?",
   "id": "95d070fc5f909b39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:29:21.992870Z",
     "start_time": "2024-05-17T12:29:18.658688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_clf, y_train_clf = load_basic_motions(split=\"train\")\n",
    "X_test_clf, y_test_clf = load_basic_motions(split=\"test\")\n",
    "clf = make_pipeline(MiniRocketMultivariate(n_jobs=1),\n",
    "                    StandardScaler(),LogisticRegressionCV(n_jobs=-1, max_iter=1000))\n",
    "\n",
    "clf.fit(X_train_clf, y_train_clf)\n",
    "print(\"accuracy is\", clf.score(X_test_clf,y_test_clf) )"
   ],
   "id": "764d428726d3dcb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 1.0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:29:27.294283Z",
     "start_time": "2024-05-17T12:29:21.997876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_to_explain = 40\n",
    "myFA4clf = Feature_Ablation(clf)\n",
    "exp = myFA4clf.explain(X_train_clf[:n_to_explain],labels=y_test_clf[:n_to_explain],n_segments=7)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\")"
   ],
   "id": "490ed0814d9c69b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:05<00:00,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (1680,) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:30:05.840418Z",
     "start_time": "2024-05-17T12:29:27.296739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp = myFA4clf.explain(X_train_clf[:n_to_explain],labels=y_test_clf[:n_to_explain])\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\")\n"
   ],
   "id": "4cc64c1ccd09e0c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:38<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (23911,) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# regression  task",
   "id": "e37f1bf6f7cd0339"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:30:06.393631Z",
     "start_time": "2024-05-17T12:30:05.842502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "regressor = make_pipeline(MiniRocketMultivariate(n_jobs=1),\n",
    "                    StandardScaler(),LinearRegression(n_jobs=-1))\n",
    "\n",
    "regressor.fit(X_train_reg, y_train_reg)\n",
    "print(\"metric is\", regressor.score(X_test_reg,y_test_reg) )"
   ],
   "id": "5725fdcd9298b29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric is 0.5771726659034571\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:30:15.666055Z",
     "start_time": "2024-05-17T12:30:06.395615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_to_explain = 20\n",
    "myLime4reg = LIME(regressor)\n",
    "exp = myLime4reg.explain(X_train_reg[:n_to_explain] ,batch_size=4)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\")"
   ],
   "id": "ca0696053e246fbc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/workspace/PhD/captum4aeon/tsCaptum/explainers.py:117: UserWarning:  batch_size set to 1 as suggested by Captum for Lime and KernelSHAP\n",
      "  warnings.warn(\" batch_size set to 1 as suggested by Captum for Lime and KernelSHAP\")\n",
      "100%|██████████| 20/20 [00:09<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (722,) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:30:18.936771Z",
     "start_time": "2024-05-17T12:30:15.668225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp= myLime4reg.explain(X_train_reg[:n_to_explain] ,batch_size=4, n_segments=10)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\",)"
   ],
   "id": "a96f0fc5350590a9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davide/workspace/PhD/captum4aeon/tsCaptum/explainers.py:117: UserWarning:  batch_size set to 1 as suggested by Captum for Lime and KernelSHAP\n",
      "  warnings.warn(\" batch_size set to 1 as suggested by Captum for Lime and KernelSHAP\")\n",
      " 30%|███       | 6/20 [00:00<00:02,  6.33it/s]/home/davide/miniconda3/envs/TSCaptum/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e-02, tolerance: 1.407e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|██████████| 20/20 [00:03<00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> unique values (501,) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Shapely Value Sampling\n",
    "I thought let called it 'Shapely Value Sampling' in the library source code and import it as SHAP in the examples/tutorials for this code"
   ],
   "id": "622e481fd9502d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:30:19.543178Z",
     "start_time": "2024-05-17T12:30:18.938377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "regressor = make_pipeline(MiniRocketMultivariate(n_jobs=1),\n",
    "                          StandardScaler(),LinearRegression(n_jobs=-1))\n",
    "\n",
    "regressor.fit(X_train_reg, y_train_reg)\n",
    "print(\"metric is\", regressor.score(X_test_reg,y_test_reg) )"
   ],
   "id": "451de79f277a21b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric is 0.5788203574161792\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-17T12:30:19.547124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tsCaptum.explainers import Shapley_Value_Sampling as SHAP\n",
    "n_to_explain = 4\n",
    "mySHAP4reg = SHAP(regressor)\n",
    "exp = mySHAP4reg.explain(X_train_reg[:n_to_explain] ,batch_size=2)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\")"
   ],
   "id": "126b52d3b02c48a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "exp = mySHAP4reg.explain(X_train_reg[:n_to_explain] ,batch_size=2, n_segments=5)\n",
    "print( type(exp),\"unique values\", np.unique(exp).shape , \"\\n\\n\")"
   ],
   "id": "8d97e930cbc27c2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fafef928b901b055"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
